parameters:
  rancher_monitoring:
    =_metadata:
      library_aliases:
        prom.libsonnet: rancher-monitoring-prom.libsonnet
    namespace: syn-rancher-monitoring

    kube_prometheus_version:
      '1.15': release-0.3
      '1.16': release-0.4
      '1.17': release-0.4
      '1.18': release-0.6
      '1.19': release-0.7
      '1.20': release-0.8
      '1.21': release-0.9
      '1.22': release-0.10
      '1.23': release-0.11
    cluster_kubernetes_version: '1.18'
    jsonnetfile_parameters:
      kube_prometheus_version: ${rancher_monitoring:kube_prometheus_version:${rancher_monitoring:cluster_kubernetes_version}}

    =_federation_target_map:
      'v1': access-prometheus.cattle-prometheus.svc.cluster.local:80
      'v2': prometheus-operated.cattle-monitoring-system.svc.cluster.local:9090
    rancher_monitoring_version: 'v2'
    federation_target: ${rancher_monitoring:_federation_target_map:${rancher_monitoring:rancher_monitoring_version}}

    prometheusServiceType: ClusterIP
    prometheusInstance: platform
    prometheus:
      evaluationInterval: 5s
      scrapeInterval: 10s
      replicas: 1
      resources:
        requests:
          memory: 2Gi
          cpu: 1000m
        limits:
          memory: 6Gi
          cpu: 2000m
      retention: 24h
      storage:
        volumeClaimTemplate:
          spec:
            accessModes:
              - ReadWriteOnce
            storageClassName: fast
            resources:
              requests:
                storage: 10Gi

    alertmanagerInstance: platform
    alertmanager:
      replicas: 1
      logLevel: info

    # alertmanagerConfig is rendered as is into the alertmanager config secret
    alertmanagerConfig:
      receivers:
        # blackhole receiver for alerts we don't care about
        - name: devnull
      # If the user doesn't configure a receiver, send everything to
      # devnull. This allows Alertmanager to start even if the user doesn't
      # configure any alert receivers.
      route:
        receiver: devnull
        group_wait: 0s
        group_interval: 5s
        repeat_interval: 10m

    thanos: {}

    =_federation_job_map:
      v1:
        - expose-kubelets-metrics
        - expose-kubernetes-metrics
        - expose-node-metrics
        - expose-prometheus-metrics
        - kubernetes

      v2:
        - apiserver
        - coredns
        - kube-controller-manager
        - kube-etcd
        - kube-proxy
        - kube-scheduler
        - kube-state-metrics
        - kubelet
        - node-exporter
        - rancher-monitoring-prometheus

    federation:
      interval: '10s'
      scrape_timeout: '10s'
      jobs: ${rancher_monitoring:_federation_job_map:${rancher_monitoring:rancher_monitoring_version}}
      extra_metric_relabel_configs: []

    alerts:
      namespaceSelector: namespace=~"default|((kube|syn|cattle).*)"
      # List of alertnames to exclude from the final ruleset
      ignoreNames: []
      customAnnotations: {}
      # Storageclasses that share the same volume for each PV and will only
      # be alerted for once when filling up.
      sharedStorageClass: ""

    images:
      prometheus:
        image: 'quay.io/prometheus/prometheus'
        tag: 'v2.38.0@sha256:aa1687dd552ed98df598cc0fed2effbc62a0f05236bc2253c65520ddd4f2afce'
      alertmanager:
        image: quay.io/prometheus/alertmanager
        tag: 'v0.23.0'
      thanos:
        image: quay.io/thanos/thanos'
        tag: v0.18.0
    rules: {}
